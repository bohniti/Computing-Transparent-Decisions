\newglossaryentry{relu}
{
 name=Pooling Layer,
 description={n the context of artificial neural networks, the rectifier is an activation function defined as the positive part of its argument: where x is the input to a neuron. This is also known as a ramp function and is analogous to half-wave rectification in electrical engineering.}
}
\newglossaryentry{pl}
{
 name=Pooling Layer,
 description={A pooling layer is another building block of a CNN. Its function is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network. }
}
\newglossaryentry{cnn}
{
 name=Convolutional Neural Networks,
 description={In  deep learning, a convolutional neural network is a class of deep neural networks, most commonly applied to analyzing visual imagery. They are also known as shift invariant or space invariant artificial neural networks, based on their shared-weights architecture and translation invariance characteristics.}
}
\newglossaryentry{dnn}
{
 name=Deep Neural Network,
 description={A \Gls{nn} with more than one layer}
}
\newglossaryentry{nn}
{
 name=Artificial Neural Network,
 description={Artificial neural networks or connectionist systems are computing systems vaguely inspired by the biological neural networks that constitute animal brains. Such systems "learn" to perform tasks by considering examples, generally without being programmed with task-specific rules.}
}
\newglossaryentry{sf}
{
 name=Sigmoid Function,
 description={A sigmoid function is a mathematical function having a characteristic "S"-shaped curve or sigmoid curve. A common example of a sigmoid function is the logistic function shown in the first figure and defined by the formula: Other standard sigmoid functions are given in the Examples section}
}
\newglossaryentry{cf}
{
 name=Cost Function,
 description={Sum of all single values which came from a \Gls{lf}}
}
\newglossaryentry{lf}
{
 name=Loss Function,
 description={In mathematical optimization and decision theory, a loss function or cost function is a function that maps an event or values of one or more variables onto a real number intuitively representing some "cost" associated with the event.}
}
\newglossaryentry{lr}
{
 name=Logistic Regression,
 description={In statistics, the logistic model is used to model the probability of a certain class or event existing such as pass/fail, win/lose, alive/dead or healthy/sick. This can be extended to model several classes of events such as determining whether an image contains a cat, dog, lion, etc.}
}
\newglossaryentry{ai}
{
 name=Artifical Intelligence,
 description={Deep learning is part of a broader family of machine learning methods based on artificial neural networks with representation learning. Learning can be supervised, semi-supervised or unsupervised}
}
\newglossaryentry{dl}
{
 name=Deep Learning,
 description={Deep learning is part of a broader family of machine learning methods based on artificial neural networks with representation learning. Learning can be supervised, semi-supervised or unsupervised}
}
\newglossaryentry{xai}
{
 name=Explainable Artificial Intelligence,
 description={Explainable AI refers to methods and techniques in the application of artificial intelligence technology such that the results of the solution can be understood by human experts.
 }
}
\newglossaryentry{ul}
{
 name=Upload Filter,
 description={An upload filter is server-side software that checks files during upload, rejects them if necessary, changes them or initiates other measures.
 }
}

\newglossaryentry{ml}
{
 name=Machine Learning,
 description={Machine learning is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence.
 }
}
\newglossaryentry{mla}
{
 name=Machine Learning Algorithm,
 description={see \Gls{ml}.
 }
}
\newglossaryentry{gpu}
{
 name=Graphical Processing Units,
 description={A graphics processing unit is a specialized electronic circuit designed to rapidly manipulate and alter memory to accelerate the creation of images in a frame buffer intended for output to a display device. GPUs are used in embedded systems, mobile phones, personal computers, workstations, and game consoles.
 }
}
\newglossaryentry{clt}
{
 name=Classification Task,
 description={Classification is the process of predicting the class of given data points. Classes are sometimes called as targets/ labels or categories. Classification predictive modeling is the task of approximating a mapping function (f) from input variables (X) to discrete output variables (y).
 }
}
\newglossaryentry{sla}
{
name=Supervised Machine Learning Algorithm,
description={Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs.
}
}
\newglossaryentry{sl}
{
 name=Supervised Learning,
 description={see \Gls{sla}.
 }
}
\newglossaryentry{td}
{
 name=Training Data,
 description={The training data is an initial set of data used to help a program understand how to apply technologies like neural networks to learn and produce sophisticated results. It may be complemented by subsequent sets of data called validation and testing sets.
 }
}
\newglossaryentry{pp}
{
 name=Preprocessing,
 description={In any Machine Learning process, Data Preprocessing is that step in which the data gets transformed, or Encoded, to bring it to such a state that now the machine can easily parse it. In other words, the features of the data can now be easily interpreted by the algorithm.
 }
}
\newglossaryentry{bias}
{
 name=Bias,
 description={Bias is just like an intercept added in a linear equation. It is an additional parameter in the Neural Network which is used to adjust the output along with the weighted sum of the inputs to the neuron. Moreover, bias value allows you to shift the activation function to either right or left.
 }
}
\newglossaryentry{af}
{
 name=Activation Functions,
 description={Activation functions are mathematical equations that determine the output of a neural network. The function is attached to each neuron in the network, and determines whether it should be activated (“fired”) or not, based on whether each neuron's input is relevant for the model's prediction.
 }
}
\newglossaryentry{gbe}
{
	name=Gradient-Based explanations,
	description={It uses the gradient to get some information of how much every feature is contributing to the data itself.
	}
}
\newglossaryentry{shap}
{
	name=SHAP Gradient Explainer,
	description={It uses the gradient to get some information of how much every feature is contributing to the data itself.
	}
}
\newglossaryentry{fp}
{
	name=Forward Propagation,
	description={First step while callculation an \gls{mla} which callculates the losses of the single outputs and sum them up to a final error value
	}
}
\newglossaryentry{bp}
{
	name=Backward Propagation,
	description={Second step while callculation an \gls{mla} which callculates the gradients of the weights in order to optimize the error value (\gls{fp})
	}
}